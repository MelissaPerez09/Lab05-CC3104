{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b4dc58",
   "metadata": {},
   "source": [
    "## Laboratorio 05 - SARSA y Q-Learning\n",
    "Integrantes:\n",
    "- Ricardo Méndez\n",
    "- Melissa Pérez\n",
    "\n",
    "Repositorio: https://github.com/MelissaPerez09/Lab05-CC3104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6c2e6",
   "metadata": {},
   "source": [
    "### Task 01\n",
    "1. Defina y explique qué “expected sarsa”\n",
    "    - Es una variante de SARSA que calcula el valor esperado de la acción siguiente ponderando todas las acciones posibles según la política actual, en lugar de usar solo la acción efectivamente tomada.\n",
    "    \n",
    "    a. ¿Cómo se diferencia de “sarsa”?\n",
    "    - La diferencia es que SARSA usa la recompensa de la acción real tomada, mientras que Expected SARSA usa el valor esperado sobre todas las acciones.\n",
    "    \n",
    "    b. ¿Para qué sirven las modificaciones que se hacen sobre “sarsa”?\n",
    "    - Sirve para reducir la varianza de las actualizaciones y mejora la estabilidad del aprendizaje.\n",
    "2. Defina y explique qué es “n-step TD”\n",
    "    - Es un Método \"Temporal Difference\" que actualiza el valor usando la suma de recompensas de `n` pasos futuros antes de estimar el valor restante.\n",
    "    \n",
    "    a. ¿Cómo se diferencia de TD(0)?\n",
    "    - `TD(0)` usa solo el siguiente paso que es `n=1`, mientras que n-step considera varios pasos intermedios.\n",
    "    \n",
    "    b. ¿Cuál es la utilidad de esta modificación?\n",
    "    - Principalmente es el balanceo de sesgo y varianza, y puede acelerar la convergencia.\n",
    "    \n",
    "    c. ¿Qué usa como objetivo?\n",
    "    - Usa un retorno de n pasos, que combina recompensas reales de los primeros n pasos y un valor estimado al paso n.\n",
    "3. ¿Cuál es la diferencia entre SARSA y Q-learning?\n",
    "    - SARSA:\n",
    "        - On-policy \n",
    "        - Aprende siguiendo y evaluando la misma política.\n",
    "    - Q-learning:\n",
    "        - Off-policy\n",
    "        - Aprende evaluando la política óptima mientras sigue otra política (ej. exploratoria)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991380f",
   "metadata": {},
   "source": [
    "### Task 02"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
